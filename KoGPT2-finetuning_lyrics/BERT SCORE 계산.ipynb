{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고 : https://github.com/Tiiiger/bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성된 가사 (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gen = pd.read_excel('./dataset/생성가사.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu_gen = gen['iu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_gen = gen['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_gen = gen['mx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가수의 기존 가사 ('시작'이 들어간 가사 일부분을 모은 데이터셋)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 아이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "D1 = pd.read_excel('./dataset/iu_start.xlsx') \n",
    "iu_D = D1['iu_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iu_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) 선우정아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "D2 = pd.read_excel('./dataset/s_start.xlsx') \n",
    "s_D = D2['s_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'시간이 낡았고모든 게 변했어도있잖아 우리는그냥 이대로 살자대단치 않아도둘이서 매일을조그맣게그림 같은 집을 짓진 못했지만It’s not romantic to cleanthe bathroom is it Hon’맘껏 뒹굴거릴 수 있으니까여긴 완전한 둘의 세계야저 바깥에서는감춰 숨겨두었던 모든 것조금 더 알을래 가까이너만 느껴지게 가까이있잖아 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) 몬스타엑스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "D3 = pd.read_excel('./dataset/mx_start.xlsx') \n",
    "mx_D = D3['mx_lyrics'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WE GO HIGH끌리는 대로 그냥 하면 돼소릴 높여 우린 하나가 돼어두웠던 시간은 꿈이 되어멋진 세상에 뛰어들어봐BOW WOW BOW WOWWE ARE SO DANGER(Refresh!)WA WA- WA WOO WA WA-WA WOO WA WAAH YEAH AH YEAHWE ARE SO DANGERWA WA- WA WOO WA WA-BOW WOW시원하게 즐겨 TASTE OF KOREAWE ARE SO DANGERWHAT'S UP WHAT'S WHAT'SWHAT'S UP WHAT'S WHAT'S WHAT'S UPUH UH UH UH UHBOW WOW BOW WOWWHAT'S UP WHAT'S WHAT'SWHAT'S UP WHAT'S WHAT'S WHAT'S UPUH UH UH UH UHWE ARE SO DANGER\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx_D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT SCORE 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert(D, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  1) 아이유-아이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba55115f399d4deea31305d771e6daa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0affe529093a4fe6be87f936820d38df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 12.42 seconds, 12.88 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "iu_iu = [[x,y] for x in iu_D for y in iu_gen]\n",
    "len(iu_iu)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(iu_iu)):\n",
    "    refs.append(iu_iu[i][0])\n",
    "    cands.append(iu_iu[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6515, 0.5779, 0.5526, 0.6216, 0.6385, 0.6040, 0.5242, 0.5375, 0.6333,\n",
      "        0.6068, 0.6358, 0.5611, 0.5486, 0.5960, 0.6304, 0.6281, 0.5573, 0.5554,\n",
      "        0.5927, 0.6094, 0.6164, 0.5377, 0.5421, 0.6421, 0.6206, 0.6271, 0.5624,\n",
      "        0.5478, 0.5955, 0.6103, 0.5919, 0.5291, 0.5423, 0.5746, 0.5820, 0.6293,\n",
      "        0.5753, 0.5721, 0.5871, 0.6074, 0.6299, 0.5784, 0.5845, 0.5976, 0.6328,\n",
      "        0.6285, 0.6045, 0.5769, 0.5742, 0.6288, 0.6131, 0.5775, 0.5684, 0.5842,\n",
      "        0.6180, 0.5943, 0.5376, 0.5620, 0.6016, 0.5846, 0.6111, 0.5564, 0.5552,\n",
      "        0.5944, 0.6194, 0.6229, 0.5549, 0.5707, 0.5905, 0.6308, 0.6483, 0.5891,\n",
      "        0.5851, 0.6235, 0.6459, 0.6108, 0.6038, 0.5796, 0.5682, 0.6158, 0.6343,\n",
      "        0.5696, 0.5836, 0.6116, 0.6261, 0.6472, 0.5654, 0.5789, 0.6276, 0.6285,\n",
      "        0.6076, 0.5507, 0.5564, 0.6062, 0.6139, 0.6386, 0.5837, 0.5715, 0.6290,\n",
      "        0.6484, 0.5744, 0.5117, 0.5268, 0.5598, 0.5723, 0.6506, 0.5784, 0.5876,\n",
      "        0.6028, 0.6418, 0.5910, 0.5675, 0.5671, 0.5797, 0.5910, 0.6056, 0.5389,\n",
      "        0.5629, 0.6136, 0.6195, 0.6623, 0.5903, 0.5871, 0.6060, 0.6474, 0.6165,\n",
      "        0.5568, 0.5576, 0.6057, 0.6164, 0.6060, 0.5547, 0.5578, 0.6022, 0.6179,\n",
      "        0.5910, 0.5675, 0.5671, 0.5797, 0.5910, 0.5872, 0.5403, 0.5547, 0.6328,\n",
      "        0.5906, 0.6163, 0.5488, 0.5497, 0.5846, 0.6061, 0.6126, 0.5433, 0.5462,\n",
      "        0.5821, 0.6201, 0.6222, 0.5541, 0.5476, 0.5865, 0.6173])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5915971"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_iu=F1\n",
    "iu_iu_array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) 아이유-선우정아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ab327a4e7f4542a28e8d7004a4850b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a8c769406a4a5b83ff5edeca746472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 22.96 seconds, 6.97 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "iu_s = [[x,y] for x in iu_D for y in s_gen]\n",
    "len(iu_s)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(iu_s)):\n",
    "    refs.append(iu_s[i][0])\n",
    "    cands.append(iu_s[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5883, 0.6344, 0.5952, 0.6299, 0.5428, 0.5683, 0.5915, 0.5678, 0.5875,\n",
      "        0.5009, 0.5945, 0.6257, 0.5864, 0.6027, 0.5294, 0.5593, 0.6108, 0.5697,\n",
      "        0.5985, 0.5077, 0.5457, 0.6023, 0.5547, 0.5947, 0.5001, 0.5625, 0.6139,\n",
      "        0.5624, 0.6076, 0.5095, 0.5385, 0.5892, 0.5613, 0.5878, 0.4923, 0.5811,\n",
      "        0.6082, 0.5848, 0.6156, 0.5195, 0.5750, 0.6188, 0.5880, 0.6240, 0.5310,\n",
      "        0.5599, 0.6623, 0.5881, 0.5733, 0.5612, 0.5701, 0.5937, 0.5655, 0.6072,\n",
      "        0.5313, 0.5494, 0.5834, 0.5419, 0.5979, 0.5004, 0.5656, 0.5898, 0.5586,\n",
      "        0.6001, 0.5155, 0.5852, 0.5997, 0.5623, 0.6325, 0.5293, 0.5993, 0.6115,\n",
      "        0.5907, 0.6523, 0.5372, 0.6025, 0.6134, 0.5923, 0.5849, 0.5510, 0.5958,\n",
      "        0.6068, 0.5819, 0.6178, 0.5529, 0.5695, 0.6214, 0.5745, 0.6155, 0.5310,\n",
      "        0.5596, 0.5989, 0.5617, 0.6210, 0.5226, 0.5733, 0.6043, 0.5836, 0.6164,\n",
      "        0.5219, 0.5419, 0.5622, 0.5572, 0.5677, 0.4756, 0.6137, 0.6090, 0.6087,\n",
      "        0.6200, 0.5441, 0.5688, 0.5804, 0.5832, 0.5662, 0.5183, 0.5548, 0.5928,\n",
      "        0.5651, 0.6074, 0.5123, 0.6039, 0.6124, 0.5999, 0.6314, 0.5459, 0.5650,\n",
      "        0.6214, 0.5814, 0.5942, 0.5193, 0.5566, 0.5927, 0.5517, 0.6039, 0.5160,\n",
      "        0.5688, 0.5804, 0.5832, 0.5662, 0.5183, 0.5514, 0.5611, 0.5498, 0.5920,\n",
      "        0.4956, 0.5495, 0.6027, 0.5675, 0.5880, 0.4973, 0.5620, 0.6140, 0.5534,\n",
      "        0.5927, 0.4975, 0.5631, 0.6035, 0.5778, 0.5945, 0.4981])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5738945"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_iu_s=F1\n",
    "iu_s_array = f1_tensor_iu_s.numpy()\n",
    "iu_s_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) 아이유-몬엑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9350a257f57d43c299db4306c27f5dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dff6e5f3f842c78ac38ad1d7f4d5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 22.44 seconds, 7.13 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "iu_mx = [[x,y] for x in iu_D for y in mx_gen]\n",
    "len(iu_s)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(iu_mx)):\n",
    "    refs.append(iu_mx[i][0])\n",
    "    cands.append(iu_mx[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5590, 0.5720, 0.5995, 0.5675, 0.5615, 0.5040, 0.5316, 0.5604, 0.5378,\n",
      "        0.5350, 0.5519, 0.5546, 0.5864, 0.5605, 0.5686, 0.5397, 0.5367, 0.5698,\n",
      "        0.5402, 0.5385, 0.5210, 0.5232, 0.5464, 0.5315, 0.5212, 0.5334, 0.5368,\n",
      "        0.5585, 0.5372, 0.5422, 0.5014, 0.5137, 0.5642, 0.5259, 0.5419, 0.5509,\n",
      "        0.5546, 0.5838, 0.5587, 0.5616, 0.5556, 0.5638, 0.5886, 0.5693, 0.5582,\n",
      "        0.5601, 0.5692, 0.5709, 0.5679, 0.5521, 0.5468, 0.5613, 0.5797, 0.5657,\n",
      "        0.5582, 0.5258, 0.5241, 0.5444, 0.5188, 0.5145, 0.5179, 0.5417, 0.5673,\n",
      "        0.5600, 0.5674, 0.5360, 0.5556, 0.5891, 0.5588, 0.5537, 0.5600, 0.5705,\n",
      "        0.6009, 0.5792, 0.5883, 0.5613, 0.5863, 0.5908, 0.5683, 0.5761, 0.5615,\n",
      "        0.5578, 0.5925, 0.5687, 0.5534, 0.5323, 0.5407, 0.5674, 0.5555, 0.5413,\n",
      "        0.5249, 0.5378, 0.5777, 0.5526, 0.5479, 0.5390, 0.5532, 0.5770, 0.5669,\n",
      "        0.5480, 0.4837, 0.5138, 0.5626, 0.5428, 0.5525, 0.5752, 0.5792, 0.6017,\n",
      "        0.5910, 0.5759, 0.5320, 0.5559, 0.5624, 0.5481, 0.5810, 0.5203, 0.5309,\n",
      "        0.5654, 0.5410, 0.5360, 0.5596, 0.5716, 0.5986, 0.5661, 0.5632, 0.5147,\n",
      "        0.5330, 0.5691, 0.5485, 0.5465, 0.5209, 0.5227, 0.5610, 0.5364, 0.5279,\n",
      "        0.5320, 0.5559, 0.5624, 0.5481, 0.5810, 0.5140, 0.5194, 0.5428, 0.5297,\n",
      "        0.5112, 0.4998, 0.5246, 0.5565, 0.5300, 0.5525, 0.4933, 0.5369, 0.5638,\n",
      "        0.5330, 0.5370, 0.5122, 0.5367, 0.5698, 0.5425, 0.5654])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55090857"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_iu_mx=F1\n",
    "iu_mx_array = f1_tensor_iu_mx.numpy()\n",
    "iu_mx_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) 선우정아- 아이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d252be084544915875da9a4d3fc39f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f75a28bd86b491faffca80e476732dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 11.28 seconds, 12.85 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "s_iu = [[x,y] for x in s_D for y in iu_gen]\n",
    "len(s_iu)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(s_iu)):\n",
    "    refs.append(s_iu[i][0])\n",
    "    cands.append(s_iu[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5952, 0.5217, 0.5520, 0.5850, 0.5803, 0.6086, 0.5266, 0.5289, 0.5690,\n",
      "        0.6043, 0.6257, 0.5844, 0.5971, 0.6068, 0.6277, 0.6627, 0.6163, 0.5936,\n",
      "        0.6005, 0.6369, 0.6333, 0.5570, 0.5594, 0.5842, 0.6278, 0.5905, 0.5333,\n",
      "        0.5560, 0.6074, 0.5793, 0.5731, 0.5211, 0.5263, 0.5945, 0.5680, 0.6288,\n",
      "        0.5667, 0.5688, 0.6077, 0.6389, 0.6043, 0.5579, 0.5462, 0.5763, 0.6172,\n",
      "        0.6054, 0.5784, 0.5575, 0.5936, 0.6116, 0.6243, 0.6280, 0.5981, 0.5779,\n",
      "        0.6071, 0.6140, 0.5507, 0.5498, 0.5790, 0.5987, 0.6286, 0.5478, 0.5573,\n",
      "        0.6347, 0.6173, 0.6264, 0.5781, 0.5663, 0.6042, 0.6251, 0.6185, 0.5556,\n",
      "        0.5684, 0.6018, 0.6139, 0.5900, 0.5632, 0.5448, 0.6318, 0.5954, 0.6099,\n",
      "        0.5380, 0.5432, 0.5865, 0.6048, 0.6321, 0.5664, 0.5681, 0.6081, 0.6399,\n",
      "        0.6428, 0.6441, 0.6043, 0.6152, 0.6280, 0.5646, 0.5385, 0.5511, 0.5933,\n",
      "        0.5715, 0.6077, 0.5918, 0.5788, 0.5999, 0.6146, 0.6270, 0.5570, 0.5723,\n",
      "        0.6040, 0.6105, 0.6158, 0.5582, 0.5460, 0.5927, 0.6265, 0.6315, 0.5563,\n",
      "        0.5603, 0.6079, 0.6278, 0.6295, 0.5529, 0.5796, 0.6029, 0.6226, 0.6192,\n",
      "        0.5383, 0.5420, 0.6077, 0.5995, 0.6352, 0.5596, 0.5839, 0.6052, 0.6296,\n",
      "        0.6373, 0.5635, 0.5588, 0.6416, 0.6298, 0.6183, 0.5531, 0.5463, 0.5930,\n",
      "        0.6214])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5910249"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_s_iu=F1\n",
    "s_iu_array = f1_tensor_s_iu.numpy()\n",
    "s_iu_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) 선우정아 - 선우정아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd177bfdcda4d0bb0365800c0bbbcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cc86d84331425c934422520ef225dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 21.39 seconds, 6.78 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "s_s = [[x,y] for x in s_D for y in s_gen]\n",
    "len(s_s)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(s_s)):\n",
    "    refs.append(s_s[i][0])\n",
    "    cands.append(s_s[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5485, 0.5857, 0.5662, 0.5767, 0.4940, 0.5973, 0.5994, 0.5694, 0.5977,\n",
      "        0.5106, 0.5808, 0.6465, 0.5828, 0.6175, 0.5586, 0.5891, 0.6429, 0.5990,\n",
      "        0.6207, 0.5738, 0.5925, 0.6252, 0.5805, 0.6319, 0.5357, 0.5486, 0.5627,\n",
      "        0.5595, 0.5790, 0.4979, 0.5548, 0.5584, 0.5529, 0.5681, 0.4885, 0.5825,\n",
      "        0.6316, 0.5779, 0.6141, 0.5348, 0.6166, 0.5818, 0.6270, 0.5988, 0.5317,\n",
      "        0.5724, 0.6216, 0.5705, 0.6091, 0.5393, 0.5785, 0.6111, 0.5985, 0.6076,\n",
      "        0.5861, 0.6019, 0.5919, 0.5969, 0.6207, 0.5195, 0.5494, 0.5998, 0.5658,\n",
      "        0.5837, 0.4999, 0.5883, 0.6027, 0.5666, 0.6211, 0.5324, 0.5760, 0.6009,\n",
      "        0.5663, 0.6227, 0.5344, 0.5464, 0.5867, 0.5516, 0.5871, 0.5196, 0.5884,\n",
      "        0.6121, 0.5798, 0.6135, 0.5196, 0.5838, 0.6310, 0.5769, 0.6119, 0.5345,\n",
      "        0.5905, 0.6186, 0.6134, 0.6426, 0.5854, 0.5620, 0.5659, 0.5763, 0.5618,\n",
      "        0.5035, 0.5699, 0.5935, 0.5878, 0.6045, 0.5482, 0.5559, 0.6098, 0.5650,\n",
      "        0.5979, 0.5357, 0.5923, 0.5916, 0.5881, 0.6196, 0.5223, 0.5798, 0.6352,\n",
      "        0.5675, 0.5911, 0.5379, 0.5789, 0.6049, 0.5759, 0.6326, 0.5192, 0.5509,\n",
      "        0.6102, 0.5552, 0.5963, 0.5272, 0.5925, 0.6087, 0.5810, 0.6461, 0.5254,\n",
      "        0.5893, 0.6263, 0.5738, 0.6293, 0.5380, 0.5841, 0.6276, 0.5718, 0.6064,\n",
      "        0.5296])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57974726"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_s_s=F1\n",
    "s_s_array = f1_tensor_s_s.numpy()\n",
    "s_s_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) 선우정아 - 몬엑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7555d90105544375bf0411ea9a4c4cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e789f60d4047ca9170dbad89b4b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 21.77 seconds, 6.66 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "s_mx = [[x,y] for x in s_D for y in mx_gen]\n",
    "len(s_mx)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(s_mx)):\n",
    "    refs.append(s_mx[i][0])\n",
    "    cands.append(s_mx[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5187, 0.5322, 0.5465, 0.5325, 0.5305, 0.5111, 0.5675, 0.5926, 0.5666,\n",
      "        0.5660, 0.5606, 0.5827, 0.5932, 0.5759, 0.5619, 0.5749, 0.5923, 0.5940,\n",
      "        0.6019, 0.5791, 0.5497, 0.5768, 0.6005, 0.5678, 0.5699, 0.5106, 0.5248,\n",
      "        0.5384, 0.5253, 0.5144, 0.5037, 0.5254, 0.5414, 0.5158, 0.5315, 0.5473,\n",
      "        0.5622, 0.5799, 0.5621, 0.5576, 0.5528, 0.5679, 0.6105, 0.5904, 0.5721,\n",
      "        0.5438, 0.5460, 0.5640, 0.5579, 0.5478, 0.5829, 0.5870, 0.5778, 0.5799,\n",
      "        0.5803, 0.5305, 0.5932, 0.6075, 0.5806, 0.5739, 0.5157, 0.5381, 0.5605,\n",
      "        0.5209, 0.5239, 0.5463, 0.5550, 0.5737, 0.5519, 0.5670, 0.5319, 0.5554,\n",
      "        0.5794, 0.5548, 0.5444, 0.5230, 0.5212, 0.5355, 0.5262, 0.5207, 0.5215,\n",
      "        0.5876, 0.5925, 0.5724, 0.5620, 0.5471, 0.5604, 0.5798, 0.5610, 0.5570,\n",
      "        0.5960, 0.6019, 0.6075, 0.6311, 0.5918, 0.5189, 0.5404, 0.5627, 0.5370,\n",
      "        0.5556, 0.5682, 0.5843, 0.5757, 0.5833, 0.5689, 0.5337, 0.5403, 0.5590,\n",
      "        0.5461, 0.5301, 0.5403, 0.5645, 0.5989, 0.5661, 0.5634, 0.5269, 0.5526,\n",
      "        0.5741, 0.5516, 0.5396, 0.5414, 0.5525, 0.5738, 0.5553, 0.5522, 0.5166,\n",
      "        0.5330, 0.5501, 0.5306, 0.5187, 0.5431, 0.5647, 0.5910, 0.5618, 0.5689,\n",
      "        0.5402, 0.5597, 0.5918, 0.5615, 0.5679, 0.5506, 0.5720, 0.5722, 0.5594,\n",
      "        0.5552])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5580295"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_s_mx=F1\n",
    "s_mx_array = f1_tensor_s_mx.numpy()\n",
    "s_mx_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7) 몬엑 - 아이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c314612750684cfea72acc59d069db92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998a90fbfc4c4622a23f9479e5455e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 21.78 seconds, 10.79 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "mx_iu = [[x,y] for x in mx_D for y in iu_gen]\n",
    "len(mx_iu)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(mx_iu)):\n",
    "    refs.append(mx_iu[i][0])\n",
    "    cands.append(mx_iu[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5812, 0.5739, 0.5431, 0.5541, 0.5853, 0.5823, 0.5148, 0.5311, 0.5641,\n",
      "        0.5797, 0.6102, 0.5480, 0.5373, 0.6161, 0.6114, 0.5831, 0.5274, 0.5262,\n",
      "        0.5729, 0.5808, 0.6133, 0.5318, 0.5350, 0.5708, 0.5974, 0.5873, 0.5334,\n",
      "        0.5383, 0.5867, 0.5897, 0.6227, 0.5483, 0.5594, 0.6014, 0.6098, 0.5990,\n",
      "        0.5433, 0.5337, 0.5800, 0.5964, 0.6411, 0.5583, 0.5671, 0.6074, 0.6309,\n",
      "        0.5985, 0.5279, 0.5355, 0.6335, 0.5982, 0.6484, 0.5664, 0.5813, 0.6015,\n",
      "        0.6292, 0.6034, 0.5318, 0.5331, 0.6286, 0.5952, 0.5857, 0.5309, 0.5319,\n",
      "        0.5762, 0.5810, 0.5990, 0.5389, 0.5389, 0.5639, 0.5973, 0.6265, 0.5478,\n",
      "        0.5407, 0.5847, 0.6181, 0.6194, 0.5454, 0.5569, 0.5887, 0.6087, 0.6070,\n",
      "        0.5459, 0.5623, 0.5827, 0.6122, 0.6115, 0.5612, 0.5579, 0.5869, 0.6144,\n",
      "        0.6134, 0.5642, 0.5516, 0.6518, 0.6126, 0.6067, 0.5516, 0.5555, 0.6085,\n",
      "        0.6039, 0.5849, 0.5700, 0.5516, 0.6312, 0.5865, 0.5858, 0.5280, 0.5312,\n",
      "        0.6206, 0.5809, 0.6255, 0.5626, 0.5766, 0.6005, 0.6267, 0.6129, 0.5469,\n",
      "        0.5356, 0.5841, 0.6051, 0.6294, 0.5699, 0.5664, 0.6164, 0.6381, 0.6402,\n",
      "        0.5553, 0.5570, 0.6197, 0.6379, 0.6288, 0.5539, 0.5624, 0.6073, 0.6200,\n",
      "        0.6054, 0.5497, 0.5481, 0.5722, 0.6077, 0.5940, 0.5331, 0.5420, 0.6110,\n",
      "        0.5935, 0.5997, 0.5747, 0.5673, 0.5773, 0.5971, 0.5781, 0.5209, 0.5369,\n",
      "        0.5638, 0.5817, 0.6157, 0.5550, 0.5521, 0.6121, 0.6215, 0.5882, 0.5469,\n",
      "        0.5302, 0.6451, 0.5856, 0.6161, 0.5662, 0.5654, 0.5894, 0.6066, 0.5603,\n",
      "        0.5265, 0.5308, 0.5894, 0.5598, 0.5936, 0.5432, 0.5595, 0.5825, 0.5940,\n",
      "        0.6195, 0.5548, 0.5466, 0.6017, 0.6253, 0.5895, 0.5489, 0.5301, 0.6427,\n",
      "        0.5839, 0.5990, 0.5371, 0.5595, 0.6251, 0.5847, 0.6175, 0.5378, 0.5381,\n",
      "        0.5704, 0.6033, 0.6051, 0.5665, 0.5631, 0.5937, 0.6112, 0.6436, 0.5775,\n",
      "        0.5773, 0.6116, 0.6285, 0.6093, 0.5383, 0.5437, 0.5771, 0.6039, 0.6317,\n",
      "        0.5930, 0.5834, 0.5852, 0.6194, 0.6405, 0.5733, 0.5861, 0.6189, 0.6317,\n",
      "        0.5978, 0.5373, 0.5321, 0.5811, 0.5984, 0.6281, 0.5827, 0.5776, 0.5949,\n",
      "        0.6314])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5820906"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_mx_iu=F1\n",
    "mx_iu_array = f1_tensor_mx_iu.numpy()\n",
    "mx_iu_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8) 몬엑 - 선우정아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc65747c2ea240c28047a1205ac777de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9159cb9d3ed642c4af169f751c11ff66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 33.24 seconds, 7.07 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "mx_s = [[x,y] for x in mx_D for y in s_gen]\n",
    "len(mx_s)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(mx_s)):\n",
    "    refs.append(mx_s[i][0])\n",
    "    cands.append(mx_s[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6220, 0.5470, 0.5900, 0.5723, 0.5529, 0.5797, 0.5563, 0.5668, 0.5845,\n",
      "        0.4815, 0.5781, 0.5920, 0.5703, 0.5831, 0.5007, 0.6045, 0.5758, 0.5984,\n",
      "        0.5746, 0.4945, 0.5939, 0.5885, 0.5742, 0.6117, 0.5142, 0.5657, 0.5675,\n",
      "        0.5706, 0.5725, 0.4849, 0.5779, 0.5986, 0.5627, 0.6020, 0.5187, 0.6157,\n",
      "        0.5612, 0.5936, 0.5925, 0.5081, 0.5913, 0.6212, 0.5840, 0.6396, 0.5342,\n",
      "        0.5518, 0.5899, 0.5599, 0.5849, 0.4905, 0.5669, 0.6369, 0.5898, 0.6007,\n",
      "        0.5314, 0.5675, 0.5865, 0.5539, 0.5778, 0.4921, 0.5654, 0.5893, 0.5464,\n",
      "        0.5734, 0.4986, 0.5809, 0.5684, 0.5735, 0.6009, 0.5155, 0.6013, 0.6032,\n",
      "        0.6027, 0.6042, 0.5233, 0.5756, 0.6045, 0.5802, 0.6112, 0.5192, 0.5840,\n",
      "        0.5911, 0.5822, 0.6061, 0.5165, 0.6253, 0.5910, 0.6052, 0.6281, 0.5235,\n",
      "        0.5546, 0.5860, 0.5504, 0.5963, 0.4979, 0.5683, 0.6063, 0.5753, 0.6201,\n",
      "        0.5248, 0.5441, 0.5865, 0.5808, 0.5726, 0.5251, 0.5524, 0.5612, 0.5484,\n",
      "        0.5648, 0.5098, 0.5963, 0.6149, 0.5774, 0.6444, 0.5384, 0.5864, 0.5893,\n",
      "        0.5616, 0.5987, 0.5141, 0.6015, 0.6058, 0.5948, 0.6070, 0.5315, 0.5911,\n",
      "        0.6026, 0.5840, 0.6333, 0.5254, 0.6055, 0.5976, 0.5766, 0.6281, 0.5207,\n",
      "        0.6137, 0.5876, 0.5825, 0.6191, 0.5298, 0.5443, 0.5944, 0.5599, 0.5667,\n",
      "        0.4953, 0.6196, 0.5908, 0.6101, 0.5930, 0.5528, 0.5812, 0.5483, 0.5730,\n",
      "        0.5871, 0.4893, 0.5994, 0.5957, 0.6019, 0.6125, 0.5131, 0.5589, 0.5669,\n",
      "        0.5656, 0.5785, 0.4981, 0.6002, 0.5878, 0.5774, 0.6104, 0.5319, 0.5533,\n",
      "        0.5450, 0.5528, 0.5403, 0.4944, 0.5648, 0.5674, 0.5687, 0.5997, 0.5027,\n",
      "        0.6091, 0.5929, 0.6002, 0.6196, 0.5218, 0.5585, 0.5677, 0.5615, 0.5730,\n",
      "        0.4977, 0.5565, 0.5662, 0.5496, 0.5709, 0.4973, 0.5957, 0.5877, 0.5781,\n",
      "        0.6119, 0.5151, 0.5887, 0.5758, 0.5702, 0.6343, 0.5349, 0.5842, 0.6248,\n",
      "        0.5784, 0.6127, 0.5292, 0.6046, 0.5876, 0.5864, 0.6206, 0.5255, 0.6105,\n",
      "        0.5996, 0.6033, 0.6132, 0.5663, 0.6090, 0.6125, 0.5965, 0.6353, 0.5409,\n",
      "        0.5797, 0.5909, 0.6021, 0.5768, 0.5051, 0.6009, 0.6021, 0.5949, 0.6479,\n",
      "        0.5559])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57341045"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_mx_s=F1\n",
    "mx_s_array = f1_tensor_mx_s.numpy()\n",
    "mx_s_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9) 몬엑-몬엑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad503c62c7394215ab04643f8dbb322a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fff32710c5404393c8ec9affd5ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 30.41 seconds, 7.73 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "mx_mx = [[x,y] for x in mx_D for y in mx_gen]\n",
    "len(mx_mx)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(mx_mx)):\n",
    "    refs.append(mx_mx[i][0])\n",
    "    cands.append(mx_mx[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5657, 0.5802, 0.5825, 0.5947, 0.5600, 0.5042, 0.5417, 0.5875, 0.5669,\n",
      "        0.5716, 0.5035, 0.5335, 0.5700, 0.5411, 0.5554, 0.5024, 0.5471, 0.5844,\n",
      "        0.5613, 0.5792, 0.5220, 0.5640, 0.6074, 0.5664, 0.5807, 0.4958, 0.5302,\n",
      "        0.5615, 0.5395, 0.5662, 0.5396, 0.5450, 0.5716, 0.5460, 0.5385, 0.5232,\n",
      "        0.5584, 0.5948, 0.5742, 0.5892, 0.5512, 0.5727, 0.5975, 0.5826, 0.5657,\n",
      "        0.5086, 0.5253, 0.5757, 0.5545, 0.5448, 0.5422, 0.5494, 0.5672, 0.5571,\n",
      "        0.5387, 0.5104, 0.5260, 0.5545, 0.5456, 0.5548, 0.5124, 0.5222, 0.5489,\n",
      "        0.5334, 0.5337, 0.5106, 0.5757, 0.5950, 0.5808, 0.5857, 0.5421, 0.5695,\n",
      "        0.6146, 0.5823, 0.5832, 0.5239, 0.5413, 0.5877, 0.5490, 0.5555, 0.5576,\n",
      "        0.5677, 0.5788, 0.5618, 0.5599, 0.5396, 0.5942, 0.6066, 0.5790, 0.6075,\n",
      "        0.5251, 0.5223, 0.5527, 0.5275, 0.5285, 0.5269, 0.5508, 0.5792, 0.5484,\n",
      "        0.5509, 0.5383, 0.5469, 0.5539, 0.5639, 0.5540, 0.5167, 0.5183, 0.5405,\n",
      "        0.5231, 0.5189, 0.5418, 0.5590, 0.6045, 0.5625, 0.5682, 0.5301, 0.5462,\n",
      "        0.5913, 0.5565, 0.5611, 0.5568, 0.5876, 0.6021, 0.6040, 0.5809, 0.5639,\n",
      "        0.5542, 0.6042, 0.5797, 0.5723, 0.5442, 0.5613, 0.5901, 0.5724, 0.5727,\n",
      "        0.5479, 0.5827, 0.6114, 0.5896, 0.5886, 0.5002, 0.5322, 0.5527, 0.5339,\n",
      "        0.5183, 0.5901, 0.6146, 0.6096, 0.6084, 0.6117, 0.5024, 0.5226, 0.5629,\n",
      "        0.5429, 0.5629, 0.5333, 0.5864, 0.6009, 0.6215, 0.5836, 0.5121, 0.5311,\n",
      "        0.5631, 0.5320, 0.5512, 0.5650, 0.5571, 0.5863, 0.5581, 0.5653, 0.5263,\n",
      "        0.5441, 0.5398, 0.5399, 0.5490, 0.5147, 0.5242, 0.5540, 0.5378, 0.5576,\n",
      "        0.5388, 0.5962, 0.6448, 0.6379, 0.5920, 0.5172, 0.5335, 0.5628, 0.5360,\n",
      "        0.5551, 0.5357, 0.5199, 0.5384, 0.5254, 0.5249, 0.5170, 0.5580, 0.6142,\n",
      "        0.5682, 0.5683, 0.5448, 0.5578, 0.5977, 0.5778, 0.5805, 0.5526, 0.5581,\n",
      "        0.5878, 0.5569, 0.5590, 0.5316, 0.5508, 0.6038, 0.5696, 0.5747, 0.5839,\n",
      "        0.5965, 0.5936, 0.5992, 0.5844, 0.5657, 0.5959, 0.6070, 0.5851, 0.5697,\n",
      "        0.5096, 0.5510, 0.5698, 0.5358, 0.5586, 0.5557, 0.5692, 0.6032, 0.5745,\n",
      "        0.5743])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55964804"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor_mx_mx=F1\n",
    "mx_mx_array = f1_tensor_mx_mx.numpy()\n",
    "mx_mx_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT(G,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbca236a4f64fdfa333b27395a1a4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438dd3d3273f423b9255496eb916cd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 1.88 seconds, 13.32 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "iu_iu = [[x,y] for x in iu_gen for y in iu_gen]\n",
    "len(iu_iu)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(iu_iu)):\n",
    "    refs.append(iu_iu[i][0])\n",
    "    cands.append(iu_iu[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.6282, 0.6238, 0.6341, 0.6938, 0.6282, 1.0000, 0.6230, 0.5828,\n",
      "        0.6173, 0.6238, 0.6230, 1.0000, 0.5918, 0.6125, 0.6341, 0.5828, 0.5918,\n",
      "        1.0000, 0.6382, 0.6938, 0.6173, 0.6125, 0.6382, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69963455"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ba3459352b431cb9db4bf499ecc270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653d7070cc864cb4b16553296b39d0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 6.07 seconds, 4.12 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in iu_gen for y in mx_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5908, 0.5960, 0.6002, 0.6076, 0.5832, 0.5910, 0.6129, 0.5900, 0.6219,\n",
      "        0.5999, 0.6029, 0.5842, 0.5649, 0.5839, 0.5575, 0.5524, 0.5634, 0.5760,\n",
      "        0.5853, 0.5473, 0.5913, 0.6023, 0.6196, 0.6110, 0.5987])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58936876"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd7138cc9384b37910f0f23e6a54b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622bea3b839140fcaa54becfc9e9a924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 6.01 seconds, 4.16 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in iu_gen for y in s_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6148, 0.6313, 0.6150, 0.6235, 0.5887, 0.6060, 0.6004, 0.6253, 0.5907,\n",
      "        0.6247, 0.5820, 0.5702, 0.5870, 0.5843, 0.5820, 0.5887, 0.5835, 0.5735,\n",
      "        0.6139, 0.5622, 0.6259, 0.6248, 0.6187, 0.6256, 0.5889])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60127753"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e993c261d5cf457fbb83551fd705252f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c789945e2a243cdbf13f6c4b7e18698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 6.43 seconds, 3.89 sentences/sec\n",
      "tensor([0.6148, 0.6060, 0.5820, 0.5887, 0.6259, 0.6313, 0.6004, 0.5702, 0.5835,\n",
      "        0.6248, 0.6150, 0.6253, 0.5870, 0.5735, 0.6187, 0.6235, 0.5907, 0.5843,\n",
      "        0.6139, 0.6256, 0.5887, 0.6247, 0.5820, 0.5622, 0.5889])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60127753"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in s_gen for y in iu_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd98b9e789946dab1f8aafcfe75d107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a4265eba6a4a718e9dcf1c75195638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 3.78 seconds, 6.61 sentences/sec\n",
      "tensor([1.0000, 0.5792, 0.6673, 0.6108, 0.6054, 0.5792, 1.0000, 0.5906, 0.6056,\n",
      "        0.5780, 0.6673, 0.5906, 1.0000, 0.6016, 0.5904, 0.6108, 0.6056, 0.6016,\n",
      "        1.0000, 0.5613, 0.6054, 0.5780, 0.5904, 0.5613, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6792102"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in s_gen for y in s_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c490b40c1ccb439aa791e17c095bd994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731061fc2ba44c34954d90389bac9a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 6.05 seconds, 4.13 sentences/sec\n",
      "tensor([0.6050, 0.6606, 0.6356, 0.6570, 0.6285, 0.5613, 0.5839, 0.6018, 0.5760,\n",
      "        0.5758, 0.6027, 0.6414, 0.6269, 0.6510, 0.6218, 0.5840, 0.5912, 0.6208,\n",
      "        0.6021, 0.5861, 0.6093, 0.6211, 0.5932, 0.6287, 0.6025])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61073786"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in s_gen for y in mx_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc7dc947d344cd1a51dfc6ff22af2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2de5aba2a9a45829f566e05fbfe97ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 5.82 seconds, 4.29 sentences/sec\n",
      "tensor([0.5908, 0.5910, 0.6029, 0.5524, 0.5913, 0.5960, 0.6129, 0.5842, 0.5634,\n",
      "        0.6023, 0.6002, 0.5900, 0.5649, 0.5760, 0.6196, 0.6076, 0.6219, 0.5839,\n",
      "        0.5853, 0.6110, 0.5832, 0.5999, 0.5575, 0.5473, 0.5987])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58936876"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in mx_gen for y in iu_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c29612847d43178d35c524aa4b1cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db6091166cf4d629b802055ab017d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 5.99 seconds, 4.18 sentences/sec\n",
      "tensor([0.6050, 0.5613, 0.6027, 0.5840, 0.6093, 0.6606, 0.5839, 0.6414, 0.5912,\n",
      "        0.6211, 0.6356, 0.6018, 0.6269, 0.6208, 0.5932, 0.6570, 0.5760, 0.6510,\n",
      "        0.6021, 0.6287, 0.6285, 0.5758, 0.6218, 0.5861, 0.6025])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61073786"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in mx_gen for y in s_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7714f477b47b4575b88a8b756eea4dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3cfb2c77cc4e3f96293ddbf9e89495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 3.01 seconds, 8.32 sentences/sec\n",
      "tensor([1.0000, 0.6333, 0.5868, 0.6211, 0.5789, 0.6333, 1.0000, 0.6303, 0.6725,\n",
      "        0.6340, 0.5868, 0.6303, 1.0000, 0.6317, 0.6157, 0.6211, 0.6725, 0.6317,\n",
      "        1.0000, 0.6218, 0.5789, 0.6340, 0.6157, 0.6218, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6980975"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "g_g = [[x,y] for x in mx_gen for y in mx_gen]\n",
    "len(g_g)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(g_g)):\n",
    "    refs.append(g_g[i][0])\n",
    "    cands.append(g_g[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT(D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c538928b1884dfba0ad202398b89225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b04dd722d64a29926936a761a44d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 7.97 seconds, 128.42 sentences/sec\n",
      "tensor([1.0000, 0.6255, 0.6643,  ..., 0.9507, 0.6603, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6421359"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in iu_D for y in iu_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393145b4ee954a68b5c680c9d699dd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f66169d9e24fbfbd9b714c3c988c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 15.00 seconds, 61.85 sentences/sec\n",
      "tensor([0.6328, 0.6200, 0.6503, 0.6447, 0.6560, 0.6235, 0.5928, 0.6632, 0.6167,\n",
      "        0.6292, 0.6026, 0.6269, 0.6484, 0.6374, 0.6565, 0.6081, 0.6482, 0.6647,\n",
      "        0.6132, 0.5888, 0.6066, 0.6517, 0.6424, 0.6642, 0.6668, 0.6459, 0.6757,\n",
      "        0.6715, 0.6550, 0.6387, 0.6124, 0.6092, 0.6002, 0.6100, 0.6581, 0.6577,\n",
      "        0.6320, 0.6043, 0.6126, 0.5619, 0.6094, 0.6730, 0.6222, 0.6300, 0.6440,\n",
      "        0.6251, 0.6317, 0.5599, 0.6397, 0.6144, 0.6261, 0.6175, 0.6396, 0.6350,\n",
      "        0.6337, 0.6352, 0.6448, 0.6265, 0.6030, 0.6241, 0.6238, 0.6176, 0.6527,\n",
      "        0.5961, 0.5949, 0.6547, 0.6059, 0.6175, 0.5988, 0.6186, 0.6168, 0.6490,\n",
      "        0.6345, 0.5993, 0.6339, 0.6523, 0.6007, 0.5876, 0.6044, 0.6170, 0.6270,\n",
      "        0.6517, 0.6429, 0.6309, 0.6503, 0.6560, 0.6409, 0.6425, 0.5910, 0.6389,\n",
      "        0.6152, 0.6349, 0.6180, 0.5993, 0.6591, 0.5900, 0.6099, 0.5910, 0.5863,\n",
      "        0.6547, 0.6747, 0.6387, 0.5978, 0.6186, 0.6573, 0.5948, 0.5880, 0.6171,\n",
      "        0.6417, 0.6135, 0.6601, 0.6559, 0.6396, 0.6642, 0.6527, 0.6180, 0.6458,\n",
      "        0.5885, 0.6182, 0.6129, 0.6111, 0.6507, 0.6428, 0.6479, 0.5796, 0.6074,\n",
      "        0.5690, 0.5879, 0.6893, 0.6279, 0.6369, 0.6398, 0.6104, 0.6492, 0.5698,\n",
      "        0.6244, 0.6095, 0.6603, 0.6032, 0.6426, 0.6415, 0.6465, 0.6383, 0.6529,\n",
      "        0.6281, 0.6518, 0.6032, 0.6208, 0.6118, 0.6098, 0.6238, 0.6132, 0.6683,\n",
      "        0.5753, 0.6183, 0.5889, 0.6034, 0.6474, 0.6791, 0.6572, 0.6095, 0.6271,\n",
      "        0.6684, 0.5776, 0.5924, 0.6357, 0.6626, 0.6090, 0.6488, 0.6782, 0.6506,\n",
      "        0.6798, 0.6612, 0.6365, 0.6388, 0.5952, 0.6125, 0.5932, 0.6254, 0.6107,\n",
      "        0.5963, 0.6535, 0.5924, 0.6072, 0.5543, 0.6117, 0.6286, 0.6437, 0.6173,\n",
      "        0.5884, 0.6206, 0.6469, 0.5646, 0.5711, 0.6148, 0.6216, 0.6044, 0.6430,\n",
      "        0.6729, 0.6204, 0.6688, 0.6403, 0.6157, 0.6240, 0.6093, 0.6285, 0.6419,\n",
      "        0.6367, 0.6143, 0.6002, 0.6602, 0.6108, 0.6123, 0.6058, 0.6213, 0.6218,\n",
      "        0.6382, 0.6516, 0.5920, 0.6218, 0.6532, 0.5729, 0.5940, 0.6313, 0.6229,\n",
      "        0.6309, 0.6617, 0.6807, 0.6221, 0.6797, 0.6497, 0.6315, 0.6141, 0.6044,\n",
      "        0.6352, 0.6597, 0.6743, 0.6286, 0.5932, 0.6533, 0.6225, 0.6505, 0.6494,\n",
      "        0.6190, 0.6232, 0.6316, 0.6338, 0.6163, 0.6194, 0.6502, 0.6082, 0.5999,\n",
      "        0.6439, 0.6296, 0.6542, 0.6558, 0.6509, 0.6330, 0.6562, 0.6624, 0.6667,\n",
      "        0.5831, 0.5788, 0.6313, 0.6747, 0.6211, 0.5646, 0.5511, 0.6394, 0.5850,\n",
      "        0.6495, 0.6336, 0.5644, 0.6027, 0.6061, 0.5953, 0.6161, 0.5852, 0.6396,\n",
      "        0.6081, 0.5695, 0.6082, 0.6187, 0.5856, 0.6401, 0.5988, 0.6090, 0.6038,\n",
      "        0.6174, 0.6407, 0.5760, 0.5914, 0.6119, 0.6370, 0.6444, 0.5879, 0.5807,\n",
      "        0.6113, 0.6041, 0.6329, 0.6332, 0.6054, 0.5969, 0.5957, 0.6294, 0.5954,\n",
      "        0.6124, 0.6117, 0.6005, 0.5758, 0.6188, 0.6072, 0.6386, 0.6136, 0.6211,\n",
      "        0.6015, 0.6326, 0.6216, 0.6488, 0.6368, 0.5852, 0.6297, 0.5822, 0.6000,\n",
      "        0.6430, 0.6272, 0.6378, 0.5766, 0.6092, 0.5667, 0.5873, 0.6347, 0.6277,\n",
      "        0.6405, 0.6071, 0.6194, 0.6349, 0.5530, 0.5935, 0.6218, 0.6572, 0.6053,\n",
      "        0.6355, 0.6564, 0.6511, 0.6423, 0.6541, 0.6161, 0.6187, 0.6154, 0.6151,\n",
      "        0.6183, 0.6238, 0.5982, 0.5923, 0.6329, 0.5827, 0.6009, 0.5721, 0.6120,\n",
      "        0.6111, 0.6433, 0.6458, 0.5789, 0.6239, 0.6290, 0.5770, 0.5838, 0.6132,\n",
      "        0.6138, 0.6048, 0.6364, 0.6455, 0.6251, 0.6521, 0.6523, 0.6239, 0.5975,\n",
      "        0.6203, 0.6275, 0.6191, 0.6659, 0.5972, 0.5867, 0.6446, 0.5975, 0.6151,\n",
      "        0.5865, 0.6326, 0.6055, 0.6304, 0.6521, 0.5809, 0.6295, 0.6414, 0.5694,\n",
      "        0.5608, 0.5965, 0.6049, 0.6361, 0.6597, 0.6545, 0.6317, 0.6690, 0.6552,\n",
      "        0.6494, 0.6196, 0.6271, 0.6407, 0.6359, 0.6676, 0.6243, 0.6000, 0.6544,\n",
      "        0.6065, 0.6310, 0.6070, 0.6462, 0.6316, 0.6566, 0.6679, 0.6026, 0.6414,\n",
      "        0.6509, 0.6109, 0.5882, 0.6318, 0.6195, 0.6427, 0.6756, 0.6774, 0.6351,\n",
      "        0.6885, 0.6827, 0.6506, 0.5613, 0.5755, 0.6025, 0.6231, 0.5962, 0.5622,\n",
      "        0.5719, 0.5920, 0.5855, 0.6059, 0.6166, 0.5720, 0.5827, 0.5999, 0.5742,\n",
      "        0.5758, 0.5852, 0.5929, 0.6029, 0.5931, 0.5975, 0.5866, 0.5782, 0.5850,\n",
      "        0.5707, 0.5707, 0.5783, 0.5851, 0.5902, 0.6062, 0.6047, 0.6218, 0.6371,\n",
      "        0.6411, 0.6308, 0.6037, 0.6504, 0.6114, 0.6276, 0.6033, 0.6357, 0.6163,\n",
      "        0.6201, 0.6440, 0.6027, 0.6330, 0.6476, 0.5834, 0.5888, 0.6069, 0.6166,\n",
      "        0.6180, 0.6675, 0.6523, 0.6279, 0.6646, 0.6531, 0.6386, 0.6678, 0.6105,\n",
      "        0.6392, 0.6478, 0.6356, 0.6421, 0.6118, 0.6779, 0.5936, 0.6337, 0.5917,\n",
      "        0.6050, 0.6601, 0.6702, 0.6510, 0.6198, 0.6352, 0.6759, 0.5917, 0.5992,\n",
      "        0.6377, 0.6783, 0.6263, 0.6906, 0.6865, 0.6698, 0.6829, 0.6820, 0.6372,\n",
      "        0.6367, 0.5881, 0.6344, 0.6003, 0.6432, 0.6316, 0.6089, 0.6544, 0.5936,\n",
      "        0.6103, 0.5862, 0.6139, 0.6524, 0.6467, 0.6523, 0.5994, 0.6317, 0.6516,\n",
      "        0.6001, 0.5992, 0.6221, 0.6397, 0.6287, 0.6579, 0.6673, 0.6391, 0.6662,\n",
      "        0.6635, 0.6257, 0.6414, 0.6078, 0.6484, 0.6114, 0.6296, 0.6374, 0.6074,\n",
      "        0.6601, 0.5929, 0.6199, 0.5956, 0.5972, 0.6589, 0.6497, 0.6480, 0.6103,\n",
      "        0.6214, 0.6570, 0.6000, 0.5943, 0.6353, 0.6428, 0.6161, 0.6561, 0.6659,\n",
      "        0.6459, 0.6629, 0.6680, 0.6226, 0.6212, 0.6047, 0.5919, 0.5712, 0.5958,\n",
      "        0.6085, 0.5866, 0.6188, 0.5848, 0.5876, 0.5511, 0.6003, 0.5933, 0.6191,\n",
      "        0.5985, 0.5675, 0.6221, 0.6134, 0.5330, 0.5906, 0.6154, 0.5966, 0.6054,\n",
      "        0.6132, 0.6503, 0.5951, 0.6444, 0.6181, 0.5973, 0.6101, 0.6178, 0.6341,\n",
      "        0.6334, 0.6356, 0.6221, 0.5984, 0.6517, 0.6196, 0.6131, 0.6035, 0.6312,\n",
      "        0.6321, 0.6335, 0.6543, 0.5931, 0.6305, 0.6535, 0.5964, 0.5840, 0.6114,\n",
      "        0.6287, 0.6349, 0.6510, 0.6548, 0.6362, 0.6569, 0.6425, 0.6476, 0.6151,\n",
      "        0.5883, 0.5995, 0.5991, 0.5909, 0.6105, 0.6206, 0.6181, 0.6025, 0.5941,\n",
      "        0.5902, 0.5762, 0.6172, 0.6066, 0.5898, 0.5905, 0.5972, 0.6206, 0.5698,\n",
      "        0.6050, 0.6106, 0.6056, 0.5826, 0.6280, 0.6064, 0.6080, 0.6104, 0.6127,\n",
      "        0.5879, 0.6554, 0.5807, 0.6316, 0.5881, 0.6309, 0.6266, 0.5941, 0.6615,\n",
      "        0.5886, 0.6051, 0.5716, 0.5873, 0.6494, 0.6472, 0.6251, 0.5978, 0.6101,\n",
      "        0.6604, 0.5632, 0.5941, 0.6295, 0.6399, 0.6125, 0.6549, 0.6844, 0.6388,\n",
      "        0.6706, 0.6488, 0.6155, 0.5990, 0.6227, 0.6335, 0.6268, 0.6515, 0.5984,\n",
      "        0.5748, 0.6364, 0.6052, 0.6167, 0.6098, 0.6379, 0.6277, 0.6375, 0.6464,\n",
      "        0.5902, 0.6192, 0.6355, 0.6097, 0.5628, 0.5956, 0.6126, 0.6277, 0.6545,\n",
      "        0.6555, 0.6129, 0.6659, 0.6446, 0.6384, 0.6440, 0.6008, 0.6447, 0.6146,\n",
      "        0.6408, 0.6272, 0.5969, 0.6726, 0.5904, 0.6206, 0.5870, 0.6188, 0.6440,\n",
      "        0.6541, 0.6540, 0.6004, 0.6294, 0.6655, 0.5811, 0.5949, 0.6237, 0.6360,\n",
      "        0.6138, 0.6755, 0.6704, 0.6371, 0.6764, 0.6732, 0.6504, 0.6388, 0.5881,\n",
      "        0.6415, 0.6060, 0.6325, 0.6449, 0.6156, 0.6553, 0.5820, 0.6321, 0.5761,\n",
      "        0.5922, 0.6403, 0.6415, 0.6456, 0.6161, 0.6150, 0.6525, 0.5760, 0.5926,\n",
      "        0.6209, 0.6470, 0.6298, 0.6692, 0.6858, 0.6556, 0.6751, 0.6748, 0.6409,\n",
      "        0.6151, 0.5883, 0.5995, 0.5991, 0.5909, 0.6105, 0.6206, 0.6181, 0.6025,\n",
      "        0.5941, 0.5902, 0.5762, 0.6172, 0.6066, 0.5898, 0.5905, 0.5972, 0.6206,\n",
      "        0.5698, 0.6050, 0.6106, 0.6056, 0.5826, 0.6280, 0.6064, 0.6080, 0.6104,\n",
      "        0.6127, 0.5879, 0.6076, 0.5672, 0.6107, 0.5922, 0.6013, 0.6588, 0.6398,\n",
      "        0.6090, 0.5704, 0.6090, 0.5741, 0.5928, 0.6556, 0.6243, 0.6166, 0.6426,\n",
      "        0.6114, 0.6090, 0.5548, 0.6226, 0.6210, 0.6305, 0.6179, 0.6180, 0.6395,\n",
      "        0.6318, 0.6400, 0.6353, 0.6174, 0.6373, 0.6003, 0.6091, 0.5950, 0.6190,\n",
      "        0.6053, 0.6022, 0.6339, 0.5759, 0.5906, 0.5724, 0.5984, 0.6285, 0.6337,\n",
      "        0.6245, 0.5758, 0.6234, 0.6322, 0.5655, 0.5903, 0.6047, 0.6358, 0.6048,\n",
      "        0.6522, 0.6399, 0.6259, 0.6467, 0.6361, 0.6012, 0.6449, 0.6262, 0.6187,\n",
      "        0.6278, 0.6638, 0.5940, 0.5810, 0.6623, 0.5739, 0.6113, 0.5675, 0.6019,\n",
      "        0.6187, 0.6537, 0.6317, 0.5879, 0.6231, 0.6564, 0.5756, 0.5918, 0.6204,\n",
      "        0.6232, 0.6114, 0.6902, 0.6877, 0.6276, 0.6910, 0.6652, 0.6379, 0.6284,\n",
      "        0.6166, 0.6068, 0.6036, 0.6347, 0.5966, 0.5942, 0.6336, 0.5865, 0.5925,\n",
      "        0.5771, 0.6112, 0.6227, 0.6333, 0.6256, 0.5713, 0.6298, 0.6332, 0.5747,\n",
      "        0.5835, 0.5956, 0.6233, 0.6141, 0.6554, 0.6360, 0.6149, 0.6491, 0.6380,\n",
      "        0.6094])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6214209"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in iu_D for y in s_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43442d2cac184237a5e93321929e9098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30029c912d3243d39c0a69239c1ad9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 31.47 seconds, 47.79 sentences/sec\n",
      "tensor([0.5615, 0.5970, 0.6332,  ..., 0.6332, 0.6343, 0.6230])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61524934"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in iu_D for y in mx_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b583db5063664a04b6a9c3a5d7895090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79b385060cd44d99d5dab8480295057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 15.51 seconds, 59.82 sentences/sec\n",
      "tensor([0.6328, 0.6387, 0.6030, 0.6425, 0.6458, 0.6518, 0.6388, 0.6240, 0.6141,\n",
      "        0.5831, 0.5760, 0.6368, 0.6187, 0.5975, 0.6196, 0.5613, 0.6062, 0.6678,\n",
      "        0.6367, 0.6414, 0.6212, 0.6101, 0.6151, 0.6554, 0.5990, 0.6440, 0.6388,\n",
      "        0.6151, 0.6076, 0.6373, 0.6449, 0.6284, 0.6200, 0.6124, 0.6241, 0.5910,\n",
      "        0.5885, 0.6032, 0.5952, 0.6093, 0.6044, 0.5788, 0.5914, 0.5852, 0.6154,\n",
      "        0.6203, 0.6271, 0.5755, 0.6047, 0.6105, 0.5881, 0.6078, 0.6047, 0.6178,\n",
      "        0.5883, 0.5807, 0.6227, 0.6008, 0.5881, 0.5883, 0.5672, 0.6003, 0.6262,\n",
      "        0.6166, 0.6503, 0.6092, 0.6238, 0.6389, 0.6182, 0.6208, 0.6125, 0.6285,\n",
      "        0.6352, 0.6313, 0.6119, 0.6297, 0.6151, 0.6275, 0.6407, 0.6025, 0.6218,\n",
      "        0.6392, 0.6344, 0.6484, 0.5919, 0.6341, 0.5995, 0.6316, 0.6335, 0.6447,\n",
      "        0.6415, 0.5995, 0.6107, 0.6091, 0.6187, 0.6068, 0.6447, 0.6002, 0.6176,\n",
      "        0.6152, 0.6129, 0.6118, 0.5932, 0.6419, 0.6597, 0.6747, 0.6370, 0.5822,\n",
      "        0.6183, 0.6191, 0.6359, 0.6231, 0.6371, 0.6478, 0.6003, 0.6114, 0.5712,\n",
      "        0.6334, 0.5991, 0.5881, 0.6268, 0.6146, 0.6060, 0.5991, 0.5922, 0.5950,\n",
      "        0.6278, 0.6036, 0.6560, 0.6100, 0.6527, 0.6349, 0.6111, 0.6098, 0.6254,\n",
      "        0.6367, 0.6743, 0.6211, 0.6444, 0.6000, 0.6238, 0.6659, 0.6676, 0.5962,\n",
      "        0.6411, 0.6356, 0.6432, 0.6296, 0.5958, 0.6356, 0.5909, 0.6309, 0.6515,\n",
      "        0.6408, 0.6325, 0.5909, 0.6013, 0.6190, 0.6638, 0.6347, 0.6235, 0.6581,\n",
      "        0.5961, 0.6180, 0.6507, 0.6238, 0.6107, 0.6143, 0.6286, 0.5646, 0.5879,\n",
      "        0.6430, 0.5982, 0.5972, 0.6243, 0.5622, 0.6308, 0.6421, 0.6316, 0.6374,\n",
      "        0.6085, 0.6221, 0.6105, 0.6266, 0.5984, 0.6272, 0.6449, 0.6105, 0.6588,\n",
      "        0.6053, 0.5940, 0.5966, 0.5928, 0.6577, 0.5949, 0.5993, 0.6428, 0.6132,\n",
      "        0.5963, 0.6002, 0.5932, 0.5511, 0.5807, 0.6272, 0.5923, 0.5867, 0.6000,\n",
      "        0.5719, 0.6037, 0.6118, 0.6089, 0.6074, 0.5866, 0.5984, 0.6206, 0.5941,\n",
      "        0.5748, 0.5969, 0.6156, 0.6206, 0.6398, 0.6022, 0.5810, 0.5942, 0.6632,\n",
      "        0.6320, 0.6547, 0.6591, 0.6479, 0.6683, 0.6535, 0.6602, 0.6533, 0.6394,\n",
      "        0.6113, 0.6378, 0.6329, 0.6446, 0.6544, 0.5920, 0.6504, 0.6779, 0.6544,\n",
      "        0.6601, 0.6188, 0.6517, 0.6181, 0.6615, 0.6364, 0.6726, 0.6553, 0.6181,\n",
      "        0.6090, 0.6339, 0.6623, 0.6336, 0.6167, 0.6043, 0.6059, 0.5900, 0.5796,\n",
      "        0.5753, 0.5924, 0.6108, 0.6225, 0.5850, 0.6041, 0.5766, 0.5827, 0.5975,\n",
      "        0.6065, 0.5855, 0.6114, 0.5936, 0.5936, 0.5929, 0.5848, 0.6196, 0.6025,\n",
      "        0.5886, 0.6052, 0.5904, 0.5820, 0.6025, 0.5704, 0.5759, 0.5739, 0.5865,\n",
      "        0.6292, 0.6126, 0.6175, 0.6099, 0.6074, 0.6183, 0.6072, 0.6123, 0.6505,\n",
      "        0.6495, 0.6329, 0.6092, 0.6009, 0.6151, 0.6310, 0.6059, 0.6276, 0.6337,\n",
      "        0.6103, 0.6199, 0.5876, 0.6131, 0.5941, 0.6051, 0.6167, 0.6206, 0.6321,\n",
      "        0.5941, 0.6090, 0.5906, 0.6113, 0.5925, 0.6026, 0.5619, 0.5988, 0.5910,\n",
      "        0.5690, 0.5889, 0.5543, 0.6058, 0.6494, 0.6336, 0.6332, 0.5667, 0.5721,\n",
      "        0.5865, 0.6070, 0.6166, 0.6033, 0.5917, 0.5862, 0.5956, 0.5511, 0.6035,\n",
      "        0.5902, 0.5716, 0.6098, 0.5870, 0.5761, 0.5902, 0.5741, 0.5724, 0.5675,\n",
      "        0.5771, 0.6269, 0.6094, 0.6186, 0.5863, 0.5879, 0.6034, 0.6117, 0.6213,\n",
      "        0.6190, 0.5644, 0.6054, 0.5873, 0.6120, 0.6326, 0.6462, 0.5720, 0.6357,\n",
      "        0.6050, 0.6139, 0.5972, 0.6003, 0.6312, 0.5762, 0.5873, 0.6379, 0.6188,\n",
      "        0.5922, 0.5762, 0.5928, 0.5984, 0.6019, 0.6112, 0.6484, 0.6730, 0.6168,\n",
      "        0.6547, 0.6893, 0.6474, 0.6286, 0.6218, 0.6232, 0.6027, 0.5969, 0.6347,\n",
      "        0.6111, 0.6055, 0.6316, 0.5827, 0.6163, 0.6601, 0.6524, 0.6589, 0.5933,\n",
      "        0.6321, 0.6172, 0.6494, 0.6277, 0.6440, 0.6403, 0.6172, 0.6556, 0.6285,\n",
      "        0.6187, 0.6227, 0.6374, 0.6222, 0.6490, 0.6747, 0.6279, 0.6791, 0.6437,\n",
      "        0.6382, 0.6316, 0.6061, 0.5957, 0.6277, 0.6433, 0.6304, 0.6566, 0.5999,\n",
      "        0.6201, 0.6702, 0.6467, 0.6497, 0.6191, 0.6335, 0.6066, 0.6472, 0.6375,\n",
      "        0.6541, 0.6415, 0.6066, 0.6243, 0.6337, 0.6537, 0.6333, 0.6565, 0.6300,\n",
      "        0.6345, 0.6387, 0.6369, 0.6572, 0.6173, 0.6516, 0.6338, 0.5953, 0.6294,\n",
      "        0.6405, 0.6458, 0.6521, 0.6679, 0.5742, 0.6440, 0.6510, 0.6523, 0.6480,\n",
      "        0.5985, 0.6543, 0.5898, 0.6251, 0.6464, 0.6540, 0.6456, 0.5898, 0.6166,\n",
      "        0.6245, 0.6317, 0.6256, 0.6081, 0.6440, 0.5993, 0.5978, 0.6398, 0.6095,\n",
      "        0.5884, 0.5920, 0.6163, 0.6161, 0.5954, 0.6071, 0.5789, 0.5809, 0.6026,\n",
      "        0.5758, 0.6027, 0.6198, 0.5994, 0.6103, 0.5675, 0.5931, 0.5905, 0.5978,\n",
      "        0.5902, 0.6004, 0.6161, 0.5905, 0.6426, 0.5758, 0.5879, 0.5713, 0.6482,\n",
      "        0.6251, 0.6339, 0.6186, 0.6104, 0.6271, 0.6206, 0.6218, 0.6194, 0.5852,\n",
      "        0.6124, 0.6194, 0.6239, 0.6295, 0.6414, 0.5852, 0.6330, 0.6352, 0.6317,\n",
      "        0.6214, 0.6221, 0.6305, 0.5972, 0.6101, 0.6192, 0.6294, 0.6150, 0.5972,\n",
      "        0.6114, 0.6234, 0.6231, 0.6298, 0.6647, 0.6317, 0.6523, 0.6573, 0.6492,\n",
      "        0.6684, 0.6469, 0.6532, 0.6502, 0.6396, 0.6117, 0.6349, 0.6290, 0.6414,\n",
      "        0.6509, 0.5929, 0.6476, 0.6759, 0.6516, 0.6570, 0.6134, 0.6535, 0.6206,\n",
      "        0.6604, 0.6355, 0.6655, 0.6525, 0.6206, 0.6090, 0.6322, 0.6564, 0.6332,\n",
      "        0.6132, 0.5599, 0.6007, 0.5948, 0.5698, 0.5776, 0.5646, 0.5729, 0.6082,\n",
      "        0.6081, 0.6005, 0.5530, 0.5770, 0.5694, 0.6109, 0.6029, 0.5834, 0.5917,\n",
      "        0.6001, 0.6000, 0.5330, 0.5964, 0.5698, 0.5632, 0.6097, 0.5811, 0.5760,\n",
      "        0.5698, 0.5548, 0.5655, 0.5756, 0.5747, 0.5888, 0.6397, 0.5876, 0.5880,\n",
      "        0.6244, 0.5924, 0.5711, 0.5940, 0.5999, 0.5695, 0.5758, 0.5935, 0.5838,\n",
      "        0.5608, 0.5882, 0.5931, 0.5888, 0.5992, 0.5992, 0.5943, 0.5906, 0.5840,\n",
      "        0.6050, 0.5941, 0.5628, 0.5949, 0.5926, 0.6050, 0.6226, 0.5903, 0.5918,\n",
      "        0.5835, 0.6066, 0.6144, 0.6044, 0.6171, 0.6095, 0.6357, 0.6148, 0.6313,\n",
      "        0.6439, 0.6082, 0.6188, 0.6218, 0.6132, 0.5965, 0.6318, 0.5975, 0.6069,\n",
      "        0.6377, 0.6221, 0.6353, 0.6154, 0.6114, 0.6106, 0.6295, 0.5956, 0.6237,\n",
      "        0.6209, 0.6106, 0.6210, 0.6047, 0.6204, 0.5956, 0.6517, 0.6261, 0.6170,\n",
      "        0.6417, 0.6603, 0.6626, 0.6216, 0.6229, 0.6296, 0.6187, 0.6072, 0.6572,\n",
      "        0.6138, 0.6049, 0.6195, 0.5866, 0.6166, 0.6783, 0.6397, 0.6428, 0.5966,\n",
      "        0.6287, 0.6056, 0.6399, 0.6126, 0.6360, 0.6470, 0.6056, 0.6305, 0.6358,\n",
      "        0.6232, 0.6233, 0.6424, 0.6175, 0.6270, 0.6135, 0.6032, 0.6090, 0.6044,\n",
      "        0.6309, 0.6542, 0.5856, 0.6386, 0.6053, 0.6048, 0.6361, 0.6427, 0.5782,\n",
      "        0.6180, 0.6263, 0.6287, 0.6161, 0.6054, 0.6349, 0.5826, 0.6125, 0.6277,\n",
      "        0.6138, 0.6298, 0.5826, 0.6179, 0.6048, 0.6114, 0.6141, 0.6642, 0.6396,\n",
      "        0.6517, 0.6601, 0.6426, 0.6488, 0.6430, 0.6617, 0.6558, 0.6401, 0.6136,\n",
      "        0.6355, 0.6364, 0.6597, 0.6756, 0.5850, 0.6675, 0.6906, 0.6579, 0.6561,\n",
      "        0.6132, 0.6510, 0.6280, 0.6549, 0.6545, 0.6755, 0.6692, 0.6280, 0.6180,\n",
      "        0.6522, 0.6902, 0.6554, 0.6668, 0.6350, 0.6429, 0.6559, 0.6415, 0.6782,\n",
      "        0.6729, 0.6807, 0.6509, 0.5988, 0.6211, 0.6564, 0.6455, 0.6545, 0.6774,\n",
      "        0.5707, 0.6523, 0.6865, 0.6673, 0.6659, 0.6503, 0.6548, 0.6064, 0.6844,\n",
      "        0.6555, 0.6704, 0.6858, 0.6064, 0.6395, 0.6399, 0.6877, 0.6360, 0.6459,\n",
      "        0.6337, 0.6309, 0.6396, 0.6465, 0.6506, 0.6204, 0.6221, 0.6330, 0.6090,\n",
      "        0.6015, 0.6511, 0.6251, 0.6317, 0.6351, 0.5707, 0.6279, 0.6698, 0.6391,\n",
      "        0.6459, 0.5951, 0.6362, 0.6080, 0.6388, 0.6129, 0.6371, 0.6556, 0.6080,\n",
      "        0.6318, 0.6259, 0.6276, 0.6149, 0.6757, 0.6352, 0.6503, 0.6642, 0.6383,\n",
      "        0.6798, 0.6688, 0.6797, 0.6562, 0.6038, 0.6326, 0.6423, 0.6521, 0.6690,\n",
      "        0.6885, 0.5783, 0.6646, 0.6829, 0.6662, 0.6629, 0.6444, 0.6569, 0.6104,\n",
      "        0.6706, 0.6659, 0.6764, 0.6751, 0.6104, 0.6400, 0.6467, 0.6910, 0.6491,\n",
      "        0.6715, 0.6448, 0.6560, 0.6527, 0.6529, 0.6612, 0.6403, 0.6497, 0.6624,\n",
      "        0.6174, 0.6216, 0.6541, 0.6523, 0.6552, 0.6827, 0.5851, 0.6531, 0.6820,\n",
      "        0.6635, 0.6680, 0.6181, 0.6425, 0.6127, 0.6488, 0.6446, 0.6732, 0.6748,\n",
      "        0.6127, 0.6353, 0.6361, 0.6652, 0.6380, 0.6550, 0.6265, 0.6409, 0.6180,\n",
      "        0.6281, 0.6365, 0.6157, 0.6315, 0.6667, 0.6407, 0.6488, 0.6161, 0.6239,\n",
      "        0.6494, 0.6506, 0.5902, 0.6386, 0.6372, 0.6257, 0.6226, 0.5973, 0.6476,\n",
      "        0.5879, 0.6155, 0.6384, 0.6504, 0.6409, 0.5879, 0.6174, 0.6012, 0.6379,\n",
      "        0.6094])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6214209"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in s_D for y in iu_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6de81283d3407fb27e4c559e13194a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2674107762343fb9dd9ca8c310ca731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 8.48 seconds, 99.15 sentences/sec\n",
      "tensor([1.0000, 0.5974, 0.6323, 0.5816, 0.5934, 0.6458, 0.6136, 0.6388, 0.5715,\n",
      "        0.5840, 0.5480, 0.5986, 0.6489, 0.6199, 0.6327, 0.5788, 0.6218, 0.6393,\n",
      "        0.5599, 0.6120, 0.6219, 0.6442, 0.5905, 0.6433, 0.6536, 0.6424, 0.6408,\n",
      "        0.6444, 0.5949, 0.5974, 1.0000, 0.5969, 0.6000, 0.6351, 0.5688, 0.5729,\n",
      "        0.6277, 0.5974, 0.5923, 0.5471, 0.6443, 0.5790, 0.6043, 0.6173, 0.5650,\n",
      "        0.6448, 0.6291, 0.5634, 0.5751, 0.5743, 0.5864, 0.6098, 0.6399, 0.6165,\n",
      "        0.6012, 0.6250, 0.6327, 0.6198, 0.6323, 0.5969, 1.0000, 0.6232, 0.6338,\n",
      "        0.6158, 0.5838, 0.6438, 0.6007, 0.6219, 0.6000, 0.6018, 0.6250, 0.6335,\n",
      "        0.6341, 0.5984, 0.6199, 0.6448, 0.5991, 0.5922, 0.6213, 0.6284, 0.6111,\n",
      "        0.6463, 0.6527, 0.6377, 0.6507, 0.6521, 0.6285, 0.5816, 0.6000, 0.6232,\n",
      "        1.0000, 0.6467, 0.5782, 0.5702, 0.6349, 0.6124, 0.6625, 0.6571, 0.6014,\n",
      "        0.5925, 0.6115, 0.6287, 0.6243, 0.6002, 0.6349, 0.6267, 0.5762, 0.6358,\n",
      "        0.6177, 0.6138, 0.6621, 0.6227, 0.6070, 0.6348, 0.6342, 0.6543, 0.5934,\n",
      "        0.6351, 0.6338, 0.6467, 1.0000, 0.5752, 0.5761, 0.6638, 0.6187, 0.6463,\n",
      "        0.6231, 0.6354, 0.5964, 0.6425, 0.6341, 0.5872, 0.6293, 0.6610, 0.5888,\n",
      "        0.5673, 0.6068, 0.6014, 0.6597, 0.6695, 0.6571, 0.6172, 0.6706, 0.6603,\n",
      "        0.6807, 0.6458, 0.5688, 0.6158, 0.5782, 0.5752, 1.0000, 0.6428, 0.6029,\n",
      "        0.5738, 0.5985, 0.5610, 0.5949, 0.6678, 0.5979, 0.6230, 0.6272, 0.6094,\n",
      "        0.6047, 0.5478, 0.6275, 0.6221, 0.6364, 0.6042, 0.6234, 0.6423, 0.6392,\n",
      "        0.6344, 0.6330, 0.6023, 0.6136, 0.5729, 0.5838, 0.5702, 0.5761, 0.6428,\n",
      "        1.0000, 0.6019, 0.5896, 0.5789, 0.5522, 0.5909, 0.6658, 0.5944, 0.6092,\n",
      "        0.6120, 0.6101, 0.6026, 0.5263, 0.6450, 0.5978, 0.6062, 0.5988, 0.6049,\n",
      "        0.6034, 0.6222, 0.6021, 0.6158, 0.5954, 0.6388, 0.6277, 0.6438, 0.6349,\n",
      "        0.6638, 0.6029, 0.6019, 1.0000, 0.6028, 0.6272, 0.6016, 0.6155, 0.6361,\n",
      "        0.6713, 0.6556, 0.5985, 0.6333, 0.9815, 0.5980, 0.5817, 0.6219, 0.6358,\n",
      "        0.6263, 0.6741, 0.6720, 0.6482, 0.6756, 0.6678, 0.6568, 0.5715, 0.5974,\n",
      "        0.6007, 0.6124, 0.6187, 0.5738, 0.5896, 0.6028, 1.0000, 0.6046, 0.5977,\n",
      "        0.6012, 0.5900, 0.5871, 0.5896, 0.5763, 0.5865, 0.6059, 0.5717, 0.5779,\n",
      "        0.5932, 0.5825, 0.6227, 0.6040, 0.5910, 0.5894, 0.5990, 0.6027, 0.6246,\n",
      "        0.5840, 0.5923, 0.6219, 0.6625, 0.6463, 0.5985, 0.5789, 0.6272, 0.6046,\n",
      "        1.0000, 0.6271, 0.5874, 0.5996, 0.6204, 0.6224, 0.8935, 0.6118, 0.6284,\n",
      "        0.5968, 0.5723, 0.6227, 0.6144, 0.6213, 0.6487, 0.6289, 0.6232, 0.6333,\n",
      "        0.6288, 0.6572, 0.5480, 0.5471, 0.6000, 0.6571, 0.6231, 0.5610, 0.5522,\n",
      "        0.6016, 0.5977, 0.6271, 1.0000, 0.5718, 0.5636, 0.6018, 0.5777, 0.5952,\n",
      "        0.5714, 0.5994, 0.6425, 0.5683, 0.5981, 0.5785, 0.6052, 0.5881, 0.5815,\n",
      "        0.5752, 0.5919, 0.5928, 0.6150, 0.5986, 0.6443, 0.6018, 0.6014, 0.6354,\n",
      "        0.5949, 0.5909, 0.6155, 0.6012, 0.5874, 0.5718, 1.0000, 0.5949, 0.5910,\n",
      "        0.6239, 0.5516, 0.7869, 0.6129, 0.5718, 0.5689, 0.5854, 0.5800, 0.6289,\n",
      "        0.6143, 0.6206, 0.5910, 0.6375, 0.6291, 0.6208, 0.6489, 0.5790, 0.6250,\n",
      "        0.5925, 0.5964, 0.6678, 0.6658, 0.6361, 0.5900, 0.5996, 0.5636, 0.5949,\n",
      "        1.0000, 0.6245, 0.6349, 0.6320, 0.6106, 0.6383, 0.5727, 0.6330, 0.6202,\n",
      "        0.6486, 0.6078, 0.6486, 0.6536, 0.6468, 0.6451, 0.6466, 0.6148, 0.6199,\n",
      "        0.6043, 0.6335, 0.6115, 0.6425, 0.5979, 0.5944, 0.6713, 0.5871, 0.6204,\n",
      "        0.6018, 0.5910, 0.6245, 1.0000, 0.6366, 0.6110, 0.6161, 0.6698, 0.6099,\n",
      "        0.5733, 0.6314, 0.6273, 0.6176, 0.6376, 0.6594, 0.6222, 0.6640, 0.6571,\n",
      "        0.6247, 0.6327, 0.6173, 0.6341, 0.6287, 0.6341, 0.6230, 0.6092, 0.6556,\n",
      "        0.5896, 0.6224, 0.5777, 0.6239, 0.6349, 0.6366, 1.0000, 0.5946, 0.6396,\n",
      "        0.6537, 0.5755, 0.5863, 0.6120, 0.6330, 0.6312, 0.6524, 0.6578, 0.6359,\n",
      "        0.6682, 0.6672, 0.6509, 0.5788, 0.5650, 0.5984, 0.6243, 0.5872, 0.6272,\n",
      "        0.6120, 0.5985, 0.5763, 0.8935, 0.5952, 0.5516, 0.6320, 0.6110, 0.5946,\n",
      "        1.0000, 0.5832, 0.6011, 0.5795, 0.5972, 0.6070, 0.6141, 0.5859, 0.6229,\n",
      "        0.6041, 0.6227, 0.6029, 0.6142, 0.6176, 0.6218, 0.6448, 0.6199, 0.6002,\n",
      "        0.6293, 0.6094, 0.6101, 0.6333, 0.5865, 0.6118, 0.5714, 0.7869, 0.6106,\n",
      "        0.6161, 0.6396, 0.5832, 1.0000, 0.6327, 0.5735, 0.5815, 0.6045, 0.6119,\n",
      "        0.6238, 0.6318, 0.6348, 0.6172, 0.6450, 0.6496, 0.6325, 0.6393, 0.6291,\n",
      "        0.6448, 0.6349, 0.6610, 0.6047, 0.6026, 0.9815, 0.6059, 0.6284, 0.5994,\n",
      "        0.6129, 0.6383, 0.6698, 0.6537, 0.6011, 0.6327, 1.0000, 0.5954, 0.5834,\n",
      "        0.6222, 0.6411, 0.6245, 0.6709, 0.6688, 0.6485, 0.6715, 0.6676, 0.6544,\n",
      "        0.5599, 0.5634, 0.5991, 0.6267, 0.5888, 0.5478, 0.5263, 0.5980, 0.5717,\n",
      "        0.5968, 0.6425, 0.5718, 0.5727, 0.6099, 0.5755, 0.5795, 0.5735, 0.5954,\n",
      "        1.0000, 0.5501, 0.5911, 0.5777, 0.5755, 0.5884, 0.5915, 0.5616, 0.6001,\n",
      "        0.6207, 0.5701, 0.6120, 0.5751, 0.5922, 0.5762, 0.5673, 0.6275, 0.6450,\n",
      "        0.5817, 0.5779, 0.5723, 0.5683, 0.5689, 0.6330, 0.5733, 0.5863, 0.5972,\n",
      "        0.5815, 0.5834, 0.5501, 1.0000, 0.6035, 0.5974, 0.5640, 0.5950, 0.5960,\n",
      "        0.5898, 0.5952, 0.5839, 0.5672, 0.6219, 0.5743, 0.6213, 0.6358, 0.6068,\n",
      "        0.6221, 0.5978, 0.6219, 0.5932, 0.6227, 0.5981, 0.5854, 0.6202, 0.6314,\n",
      "        0.6120, 0.6070, 0.6045, 0.6222, 0.5911, 0.6035, 1.0000, 0.6323, 0.6105,\n",
      "        0.6070, 0.6459, 0.6162, 0.6469, 0.6212, 0.6187, 0.6442, 0.5864, 0.6284,\n",
      "        0.6177, 0.6014, 0.6364, 0.6062, 0.6358, 0.5825, 0.6144, 0.5785, 0.5800,\n",
      "        0.6486, 0.6273, 0.6330, 0.6141, 0.6119, 0.6411, 0.5777, 0.5974, 0.6323,\n",
      "        1.0000, 0.6021, 0.6481, 0.6449, 0.6564, 0.6372, 0.6592, 0.6263, 0.5905,\n",
      "        0.6098, 0.6111, 0.6138, 0.6597, 0.6042, 0.5988, 0.6263, 0.6227, 0.6213,\n",
      "        0.6052, 0.6289, 0.6078, 0.6176, 0.6312, 0.5859, 0.6238, 0.6245, 0.5755,\n",
      "        0.5640, 0.6105, 0.6021, 1.0000, 0.6204, 0.6293, 0.6160, 0.6401, 0.6387,\n",
      "        0.6580, 0.6433, 0.6399, 0.6463, 0.6621, 0.6695, 0.6234, 0.6049, 0.6741,\n",
      "        0.6040, 0.6487, 0.5881, 0.6143, 0.6486, 0.6376, 0.6524, 0.6229, 0.6318,\n",
      "        0.6709, 0.5884, 0.5950, 0.6070, 0.6481, 0.6204, 1.0000, 0.6747, 0.6678,\n",
      "        0.6761, 0.7014, 0.6644, 0.6536, 0.6165, 0.6527, 0.6227, 0.6571, 0.6423,\n",
      "        0.6034, 0.6720, 0.5910, 0.6289, 0.5815, 0.6206, 0.6536, 0.6594, 0.6578,\n",
      "        0.6041, 0.6348, 0.6688, 0.5915, 0.5960, 0.6459, 0.6449, 0.6293, 0.6747,\n",
      "        1.0000, 0.6601, 0.9280, 0.6722, 0.6477, 0.6424, 0.6012, 0.6377, 0.6070,\n",
      "        0.6172, 0.6392, 0.6222, 0.6482, 0.5894, 0.6232, 0.5752, 0.5910, 0.6468,\n",
      "        0.6222, 0.6359, 0.6227, 0.6172, 0.6485, 0.5616, 0.5898, 0.6162, 0.6564,\n",
      "        0.6160, 0.6678, 0.6601, 1.0000, 0.6431, 0.6688, 0.6441, 0.6408, 0.6250,\n",
      "        0.6507, 0.6348, 0.6706, 0.6344, 0.6021, 0.6756, 0.5990, 0.6333, 0.5919,\n",
      "        0.6375, 0.6451, 0.6640, 0.6682, 0.6029, 0.6450, 0.6715, 0.6001, 0.5952,\n",
      "        0.6469, 0.6372, 0.6401, 0.6761, 0.9280, 0.6431, 1.0000, 0.6746, 0.6550,\n",
      "        0.6444, 0.6327, 0.6521, 0.6342, 0.6603, 0.6330, 0.6158, 0.6678, 0.6027,\n",
      "        0.6288, 0.5928, 0.6291, 0.6466, 0.6571, 0.6672, 0.6142, 0.6496, 0.6676,\n",
      "        0.6207, 0.5839, 0.6212, 0.6592, 0.6387, 0.7014, 0.6722, 0.6688, 0.6746,\n",
      "        1.0000, 0.6635, 0.5949, 0.6198, 0.6285, 0.6543, 0.6807, 0.6023, 0.5954,\n",
      "        0.6568, 0.6246, 0.6572, 0.6150, 0.6208, 0.6148, 0.6247, 0.6509, 0.6176,\n",
      "        0.6325, 0.6544, 0.5701, 0.5672, 0.6187, 0.6263, 0.6580, 0.6644, 0.6477,\n",
      "        0.6441, 0.6550, 0.6635, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6328851"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in s_D for y in s_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892c12e6ccc44b7382ab2d72a7103ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7d1e936b6a4f82b59a2171396bdaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 31.22 seconds, 43.66 sentences/sec\n",
      "tensor([0.5259, 0.6128, 0.6241,  ..., 0.6458, 0.6139, 0.6297])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61144346"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in s_D for y in mx_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0eb4192f3b470a9f40af006408f5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf4159870846da82fa4da55c700dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 29.60 seconds, 50.82 sentences/sec\n",
      "tensor([0.5615, 0.5502, 0.6052,  ..., 0.6114, 0.6245, 0.6230])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61524934"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in mx_D for y in iu_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8683274b3e4683972b3899bd2e1e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091da67aea7a4c28818cbe09e3e00bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 30.07 seconds, 45.33 sentences/sec\n",
      "tensor([0.5259, 0.5650, 0.5467,  ..., 0.6709, 0.6473, 0.6297])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61144346"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in mx_D for y in s_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b7216df5e648079053b9049e9d58bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df73ab8051f4b218433c1640d3cacfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 22.70 seconds, 97.31 sentences/sec\n",
      "tensor([1.0000, 0.5599, 0.5548,  ..., 0.6549, 0.5997, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6228754"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "d_d = [[x,y] for x in mx_D for y in mx_D]\n",
    "len(d_d)\n",
    "\n",
    "refs=[]\n",
    "cands=[]\n",
    "for i in range(len(d_d)):\n",
    "    refs.append(d_d[i][0])\n",
    "    cands.append(d_d[i][1])\n",
    "    \n",
    "P, R, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "print(F1)\n",
    "f1_tensor=F1\n",
    "array = f1_tensor.numpy()\n",
    "array.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
